<!DOCTYPE html>

<html>
<head lang="jp">
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title>Live input record and playback</title>
  <style type='text/css'>
    ul { list-style: none; }
    #recordingslist audio { display: block; margin-bottom: 10px; }
  </style>
   <link href="css/style.css" rel="stylesheet" type="text/css" />
</head>
<body>

  <h1>Record to MP3 Test</h1>

  <button onclick="startRecording(this);" class="btn btn-lg btn-primary">record</button>
  <button onclick="stopRecording(this);" disabled class="btn btn-lg btn-danger">stop</button>
  <button id="play" class="btn btn-lg btn-default">beep</button>
  
  <h2>Recordings</h2>
  <ul id="recordingslist"></ul>
  
  <h2>Log</h2>
  <pre id="log"></pre>

  <script>
  function __log(e, data) {
    log.innerHTML += "\n" + e + " " + (data || '');
  }

  var audio_context;
  var recorder;

//  function startUserMedia(stream) {
//    var input = audio_context.createMediaStreamSource(stream);
//    __log('Media stream created.' );
//	__log("input sample rate " +input.context.sampleRate);
//
//    input.connect(audio_context.destination);
//    __log('Input connected to audio context destination.');
//
//    recorder = new Recorder(input);
//    __log('Recorder initialised.');
//  }

  function startRecording(button) {
    recorder && recorder.record();
    button.disabled = true;
    button.nextElementSibling.disabled = false;
    __log('Recording...');
  }

  function stopRecording(button) {
    recorder && recorder.stop();
    button.disabled = true;
    button.previousElementSibling.disabled = false;
    __log('Stopped recording.');
    
    // create WAV download link using audio data blob
    createDownloadLink();
    
    recorder.clear();
  }

  function createDownloadLink() {
    recorder && recorder.exportWAV(function(blob) {
      /*var url = URL.createObjectURL(blob);
      var li = document.createElement('li');
      var au = document.createElement('audio');
      var hf = document.createElement('a');
      
      au.controls = true;
      au.src = url;
      hf.href = url;
      hf.download = new Date().toISOString() + '.wav';
      hf.innerHTML = hf.download;
      li.appendChild(au);
      li.appendChild(hf);
      recordingslist.appendChild(li);*/
    });
  }

//  var context;

//  var init = function() {
//      // なにはともあれAudioContextを作る。役割はその名の通り。
//      // webkitの独自実装なのでプレフィックスがつく。
//      try{
//          context = new webkitAudioContext();
//      } catch(e) {
//          console.log(e);
//      }
//      context.samplingRate = 48000;
//  }

  var src;

  var audio = function(){
      // Bufferを生成して、そこからChannelDataを取得する。
//      var buffer = audio_context.createBuffer( 1, 48000, 48000 );
//      var channel = buffer.getChannelData(0);
//
//      // ChannelDataには1サンプルごとの音声データが入る。
//      // とりあえず正弦波作って入れる。
//      for( var i=0; i < channel.length; i++ )
//      {
//          channel[i] = Math.sin( i / 100 * Math.PI);
//      }
//
//      // Sourceを作る。これが入力になる。
//      // 入力にBufferを入れる。
//      var src = audio_context.createBufferSource();
//      src.buffer = buffer;
//
//      // Modular Routing。Sourceをdest(出力)に直結する。
//      src.connect(audio_context.destination);

      // そして再生。
//      src.noteOn(audio_context.currentTime);
      src.start(audio_context.currentTime);
  }

  window.onload = function init() {
    try {
      // webkit shim
      window.AudioContext = window.AudioContext || window.webkitAudioContext;

      navigator.getUserMedia = ( navigator.getUserMedia ||
                       navigator.webkitGetUserMedia ||
                       navigator.mozGetUserMedia ||
                       navigator.msGetUserMedia);
      window.URL = window.URL || window.webkitURL;

      audio_context = new AudioContext;
      __log('Audio context set up.');
      __log('navigator.getUserMedia ' + (navigator.getUserMedia ? 'available.' : 'not present!'));
    } catch (e) {
      alert('No web audio support in this browser!');
    }

    // Bufferを生成して、そこからChannelDataを取得する。
      var buffer = audio_context.createBuffer( 1, 48000, 48000 );
      var channel = buffer.getChannelData(0);

      // ChannelDataには1サンプルごとの音声データが入る。
      // とりあえず正弦波作って入れる。
      for( var i=0; i < channel.length; i++ )
      {
          channel[i] = Math.sin( i / 100 * Math.PI);
      }

      // Sourceを作る。これが入力になる。
      // 入力にBufferを入れる。
      src = audio_context.createBufferSource();
      src.buffer = buffer;

      // Modular Routing。Sourceをdest(出力)に直結する。
      src.connect(audio_context.destination);
      recorder = new Recorder(src);
//    navigator.getUserMedia({audio: true}, startUserMedia, function(e) {
//      __log('No live audio input: ' + e);
//    });
  };

  document.querySelector("#play").addEventListener("click", function(){audio();}, false);
//  init();
  </script>
	
   <script src="js/jquery-1.11.0.min.js"></script>	
  <script src="recorder.js"></script>
</body>
</html>